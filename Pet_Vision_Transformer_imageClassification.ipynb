{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VXBA45wL4mRU"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y7MpuGCx478T",
    "outputId": "bd7d713f-ce05-491b-df9f-0328ef9b9403"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd ..\n",
    "%cd /content/drive/MyDrive\n",
    "\n",
    "zipPath = \"kagglecatsanddogs_5340.zip\"\n",
    "extractPath = \"/content/dataset\"\n",
    "\n",
    "with zipfile.ZipFile(zipPath, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extractPath)\n",
    "\n",
    "print(\"Classes:\", os.listdir(extractPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KHTgefIM5woe",
    "outputId": "bc74d04b-3eb3-4b1f-c347-f247532cdec9"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate accelerate torch torchvision tqdm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zdHw6QVL03ql"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    ViTForImageClassification,\n",
    "    AutoImageProcessor,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DefaultDataCollator\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238,
     "referenced_widgets": [
      "6aefaf6a427944bdb0cffb3e906f4736",
      "3c3f7ccb5a224d8589bb63b2578c9392",
      "0355af9192164d558085ab1c69ac97d9",
      "146692095dfe48f28d4a862722d68c2f",
      "ee46acc963dc46afa1be278a87aad4b4",
      "2eeb94bf20c841beb5d6e0f358703d28",
      "23aa01377a0b46029de7035c5eb1eeb3",
      "64106c765f1244d2bbfde969fc7a28a8",
      "bd8a831e734342ea9a8fbd7089faf65f",
      "9bb1de61f5ce45679a2a304525670ba4",
      "098d1c05536249838e7070ea3e9953f2",
      "e5b70fd5e97a41cba27717b8332611be",
      "23b3586077ee4b15bebf909da6791bdf",
      "ae13ffaeb02846a0bbd47d5ab4735acb",
      "adea3f3630a145ff9f993737cbb2b2f2",
      "9c9cc357202744c6b983a25382fc7c5e",
      "423c5b8de21042c2909d5c70aac9ffb0",
      "bc19d0233e42431087732bc8b4d57594",
      "ada8cb304d5f4fe99221be3e64cde56a",
      "f2d8a42453844586a4d5a3217fadf0d8",
      "c345473d07b1424388982776bfc5f41b",
      "e7c9068dae284e1e90934c3c90d25c53",
      "6283870f588e4e5497fd566f9817bd2d",
      "382ff8646e8d4206b049e70e5ee1370e",
      "249880bfeb644945ae77b9a1cede1753",
      "2160981ae9474b1db1d278d8f3365720",
      "b4e6dcdb56b54c148e9a956b45884731",
      "d6f9697da5ee43daa544fe9520775dba",
      "d991f3269cba401485574945f4b347ea",
      "785bf5785d6344afb785f872903faa67",
      "e3f14fc7aca9491787a5ead373ec77b3",
      "a40971ae54294031a9f1703c0b77568a",
      "0828b667c59c46f4b3c422ea40d3a9e5"
     ]
    },
    "id": "7Cy_p3061C56",
    "outputId": "1e161371-5434-424e-d511-a1ddcb38ef7d"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 1. Load & Preprocess the Cats and Dogs Dataset\n",
    "# ------------------------------------------------------------------------\n",
    "#\n",
    "# We'll assume you have a folder \"CatsAndDogs\" that contains two subfolders\n",
    "# \"cat\" and \"dog\", each with images belonging to that category.\n",
    "#\n",
    "# Make sure to set `data_dir` to the path of your dataset.\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "datasetPath = extractPath  # <-- REPLACE with the actual path to your dataset\n",
    "\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "def cleanCorruptedImagesFromFolder(rootPath):\n",
    "    deletedFiles = 0\n",
    "    categoryFolders = [\"Cat\", \"Dog\"]\n",
    "\n",
    "    for category in categoryFolders:\n",
    "        categoryPath = os.path.join(rootPath, \"PetImages\", category)\n",
    "\n",
    "        for imgName in os.listdir(categoryPath):\n",
    "            imgPath = os.path.join(categoryPath, imgName)\n",
    "            try:\n",
    "                with Image.open(imgPath) as im:\n",
    "                    im.verify()  # Ensures the image can be opened and is valid\n",
    "            except (UnidentifiedImageError, OSError):\n",
    "                os.remove(imgPath)\n",
    "                deletedFiles += 1\n",
    "\n",
    "    print(f\"Total corrupted images removed: {deletedFiles}\")\n",
    "\n",
    "# Call the function\n",
    "cleanCorruptedImagesFromFolder(extractPath)\n",
    "\n",
    "# Load the dataset from a local image folder. This will create a dataset dict\n",
    "# with a 'train' split by default if there's no explicit split directories.\n",
    "rawData = load_dataset(\"imagefolder\", data_dir=datasetPath)\n",
    "print(rawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTvMdMTD1GrU",
    "outputId": "dbf6327f-4597-4e53-cac3-fde89bd260b4"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 2. Basic Analysis (Optional)\n",
    "#    E.g., check dataset size, label names, sample example\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# def dataset_overview(dataset):\n",
    "#     # There's typically a single \"train\" split if you only have one folder structure\n",
    "#     split_names = list(dataset.keys())\n",
    "#     for split in split_names:\n",
    "#         print(f\"Split: {split}, #Samples = {len(dataset[split])}\")\n",
    "\n",
    "#     # Check label names\n",
    "#     if \"train\" in dataset:\n",
    "#         print(\"\\nAvailable Labels:\", dataset[\"train\"].features[\"label\"].names)\n",
    "\n",
    "#     # Print a sample\n",
    "#     example = dataset[\"train\"][0]\n",
    "#     print(\"\\nSample Entry:\")\n",
    "#     print(example)\n",
    "\n",
    "# dataset_overview(rawData)\n",
    "\n",
    "def displayDatasetSummary(dataDict):\n",
    "    splitList = list(dataDict.keys())\n",
    "\n",
    "    for splitName in splitList:\n",
    "        sampleCount = len(dataDict[splitName])\n",
    "        print(f\"Split: {splitName}, Total Samples: {sampleCount}\")\n",
    "\n",
    "    if \"train\" in dataDict:\n",
    "        labelOptions = dataDict[\"train\"].features[\"label\"].names\n",
    "        print(\"\\nDetected Class Labels:\", labelOptions)\n",
    "\n",
    "        sampleEntry = dataDict[\"train\"][0]\n",
    "        print(\"\\nExample Data Point:\")\n",
    "        print(sampleEntry)\n",
    "\n",
    "# Call the function\n",
    "displayDatasetSummary(rawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119,
     "referenced_widgets": [
      "64f98a3c379849b9b640b93244428e25",
      "1c4059ec212a473daefacd582e1e47eb",
      "0b2a060b82bb4029a00fddf341beb929",
      "f482fc1c11ff4ccf940734bba8b3e270",
      "61487006fa924611b988320f5d239581",
      "d5244768c8db4ef88ed88f2783b6bb16",
      "bf2b14f9aea945cda78abfd703812992",
      "d1ecaf260a81445aa56ab1f004634322",
      "32668b8677444a959733ffaa0ff5e488",
      "b4ccab69e3234d75b98e42e137a1a338",
      "025b0be8efb94056b5553f24c8ef32ad",
      "83df64913392476d8d1544b596360471",
      "3990bd560dbe48379c1fdac6defc9c28",
      "47468f582a7e4ceaa9fa80340e8969e4",
      "f451316db5924358a9b44ae932245208",
      "08d464aec5f94f14986b9c3496c2bae9",
      "eabca1389b5148e0ba4ff7a55b95db13",
      "751ae4c12d80466ab6a54ac367ade911",
      "96b4b441e1b647c3ad6aa3ad69e93c81",
      "dd3d266e8de04d34bd4adf9186e1a41e",
      "992897f8b1e54bc39f5ebfbac446e8e2",
      "d3d8bbb7170e435fbb3804cdfe093277"
     ]
    },
    "id": "3aVjlPMA1KD_",
    "outputId": "83fe0526-36c3-4910-ed5c-977a61bbac05"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 3. Define Image Processor / Transform\n",
    "#    We'll use an AutoImageProcessor for ViT that resizes and normalizes.\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# model_checkpoint = \"google/vit-base-patch16-224\"  # or any other ViT checkpoint\n",
    "# image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
    "\n",
    "# # We can get label names directly from the dataset\n",
    "# label_names = rawData[\"train\"].features[\"label\"].names\n",
    "# num_labels = len(label_names)\n",
    "# id2label = {idx: label for idx, label in enumerate(label_names)}\n",
    "# label2id = {label: idx for idx, label in enumerate(label_names)}\n",
    "\n",
    "vitCheckpoint = \"google/vit-base-patch16-224\"  # You can choose another ViT variant\n",
    "imageProcessor = AutoImageProcessor.from_pretrained(vitCheckpoint)\n",
    "\n",
    "# Extract label info from dataset\n",
    "classNames = rawData[\"train\"].features[\"label\"].names\n",
    "numClasses = len(classNames)\n",
    "\n",
    "indexToLabel = {i: name for i, name in enumerate(classNames)}\n",
    "labelToIndex = {name: i for i, name in enumerate(classNames)}\n",
    "\n",
    "# Preprocessing function to apply resizing / normalization\n",
    "# def preprocess_images(examples):\n",
    "#     images = [image.convert(\"RGB\") for image in examples[\"image\"]]\n",
    "#     inputs = imageProcessor(images=images, return_tensors=\"pt\")\n",
    "#     return inputs\n",
    "\n",
    "def processAndPrepareImage(sampleBatch):\n",
    "    rgbImages = [img.convert(\"RGB\") for img in sampleBatch[\"image\"]]\n",
    "    processedInputs = imageProcessor(images=rgbImages, return_tensors=\"pt\")\n",
    "    return processedInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N20sLs9b1Nfw",
    "outputId": "21189e13-43c4-45e9-ce84-aaf01695fb3a"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 4. Split Into Train / Validation / Test\n",
    "#    If your dataset does NOT have dedicated splits, you can split it here.\n",
    "# ------------------------------------------------------------------------\n",
    "# Example: we create an 80/10/10 split from the \"train\" data.\n",
    "\n",
    "# split_dataset = rawData[\"train\"].train_test_split(\n",
    "#     test_size=0.2, seed=42\n",
    "# )\n",
    "# # Now we have a 'train' (80%) and 'test' (20%) split.\n",
    "# # Let's further split the 20% test into half test / half validation\n",
    "# temp_dataset = split_dataset[\"test\"].train_test_split(\n",
    "#     test_size=0.5, seed=42\n",
    "# )\n",
    "\n",
    "# train_data = split_dataset[\"train\"]\n",
    "# val_data   = temp_dataset[\"train\"]\n",
    "# test_data  = temp_dataset[\"test\"]\n",
    "\n",
    "# print(\"\\nAfter splitting:\")\n",
    "# print(\"Train Data:\", len(train_data))\n",
    "# print(\"Val Data:  \", len(val_data))\n",
    "# print(\"Test Data: \", len(test_data))\n",
    "\n",
    "def splitDatasetIntoTrainValTest(datasetDict, splitRatio=0.2, seedVal=42):\n",
    "    # First split: train and remaining (20% for val+test)\n",
    "    initialSplit = datasetDict[\"train\"].train_test_split(test_size=splitRatio, seed=seedVal)\n",
    "\n",
    "    # Second split: split remaining into equal val and test\n",
    "    secondarySplit = initialSplit[\"test\"].train_test_split(test_size=0.5, seed=seedVal)\n",
    "\n",
    "    trainSet = initialSplit[\"train\"]\n",
    "    valSet   = secondarySplit[\"train\"]\n",
    "    testSet  = secondarySplit[\"test\"]\n",
    "\n",
    "    print(\"\\n After Splitting:\")\n",
    "    print(\"Training Samples:\", len(trainSet))\n",
    "    print(\"Validation Samples:\", len(valSet))\n",
    "    print(\"Test Samples:\", len(testSet))\n",
    "\n",
    "    return trainSet, valSet, testSet\n",
    "\n",
    "trainData, valData, testData = splitDatasetIntoTrainValTest(rawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 169,
     "referenced_widgets": [
      "e812e19a913c4000a43cdb96b7565795",
      "b1974d031469448fa1221db449c0a308",
      "a4197328a3334020820855e9d13f33f2",
      "7eec809d995c4d20a7d77e13d17d96e0",
      "e84d512c18524b7491612df0d0cd7a7b",
      "b500301587cf4d698d5ea65b2c8167ec",
      "fc1bbba8b60b4161beb205bca09e535a",
      "b92969235fec47198c39118c53ced59d",
      "8d9094e41e254303b200397c99a5e336",
      "9efcaa5be89e4f48afe5c7a0492b167c",
      "e88e9eff6fec44e3831872c4518ca459",
      "2e0837f361a240c1a27ce2ca494606d0",
      "cbe903727e334b8ba12e1b4574e790f3",
      "c4ea1dfafedb40dfa523d913c06a5c23",
      "70e7b40d1b314accb53c7009961b3dfb",
      "3c75bdfc68054f5b996283959f77fc15",
      "8e73f61ba33843499ee5025c944458c4",
      "73c9dd65cadb4fc9829c176082958620",
      "34fe9b100b244059a66692de78d85058",
      "cd1d982289b04eefac07eddeaf5fc6fd",
      "e57024b6d1be4213b9b580adf1ea42f8",
      "31bb605169cd4552bf0371ce9e4de3c5",
      "dab4b261a23b408fbf874f1d37473f79",
      "db5070db70c443c2a986a017bb521438",
      "61e3ab8c9de64c039da473acbc53a5f1",
      "6bcae12ff6184639a05bceb5ec9375d0",
      "de3857dd2485401c8d8feff1bbd7d91e",
      "940544e174424ed1ae75b8fedcc9fc62",
      "b0d4eed275f946aa9388f62d697d9885",
      "bbfea0b566e04e598eeb6cff17fc3919",
      "84771627e7784d05887d3a3c392659f9",
      "2b6d2588b077423c95120c490315bee4",
      "f5771431100b4a9d8d026e5ffeb5e027"
     ]
    },
    "id": "6Zgh81zp1QNw",
    "outputId": "b7dc36a4-05b8-42df-d945-8faf6529e6bc"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 5. Apply Preprocessing / Transform\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# ✅ Remove corrupted images (e.g., Cat/666.jpg)\n",
    "# from PIL import UnidentifiedImageError\n",
    "\n",
    "# def filter_valid_images(example):\n",
    "#     try:\n",
    "#         _ = example[\"image\"].convert(\"RGB\")\n",
    "#         return True\n",
    "#     except (UnidentifiedImageError, OSError):\n",
    "#         return False\n",
    "\n",
    "# train_data = train_data.filter(filter_valid_images)\n",
    "# val_data   = val_data.filter(filter_valid_images)\n",
    "# test_data  = test_data.filter(filter_valid_images)\n",
    "\n",
    "trainData = trainData.map(processAndPrepareImage, batched=True)\n",
    "valData   = valData.map(processAndPrepareImage, batched=True)\n",
    "testData  = testData.map(processAndPrepareImage, batched=True)\n",
    "\n",
    "# Remove columns we don't need so Trainer sees only the model inputs + label\n",
    "removeCol = [\"image\"]\n",
    "trainData = trainData.remove_columns(removeCol)\n",
    "valData   = valData.remove_columns(removeCol)\n",
    "testData  = testData.remove_columns(removeCol)\n",
    "\n",
    "print(\"\\nTrain data after transform:\", trainData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176,
     "referenced_widgets": [
      "5795a216af3f4f6fb6806a1eb967d05b",
      "55857876194a4835ba8da78e8cae26f3",
      "169b1c649d274857ba1f9140dee5cf10",
      "a2556d4fe1fc436595a3b89f084e0df6",
      "4841e88ee5db49c5a6cbb3939d6f6fd2",
      "42b553e05dcb4686b533a1176416b059",
      "7ca6ea70a2c9498c92138bf46a607f35",
      "8a837808ba3742c5803d8c7a9f1e739c",
      "b439cbd368814f39818cca84dc49641d",
      "b8cf6525aad54e6fac5df6a41c2c25db",
      "da9a80e7cdd74ae584f5564e103a35ca"
     ]
    },
    "id": "x9al7Xqm1TUr",
    "outputId": "1cc92dc0-a8dc-4247-cee6-bc3a2398e83a"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 6. Define the Model (ViTForImageClassification)\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    vitCheckpoint,\n",
    "    ignore_mismatched_sizes=True,\n",
    "    num_labels=numClasses,\n",
    "    id2label=indexToLabel,\n",
    "    label2id=labelToIndex\n",
    ")\n",
    "\n",
    "# Move model to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"\\nUsing device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LLbQAgyM1Za0"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 7. Define Metrics & Trainer\n",
    "# ------------------------------------------------------------------------\n",
    "# We'll compute accuracy and F1 as an example.\n",
    "\n",
    "accuracyMetric = evaluate.load(\"accuracy\")\n",
    "f1Metric       = evaluate.load(\"f1\")\n",
    "\n",
    "def computeMetric(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = accuracyMetric.compute(predictions=predictions, references=labels)\n",
    "    f1  = f1Metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    return {\n",
    "        \"accuracy\": round(acc[\"accuracy\"] * 100, 2),\n",
    "        \"f1\": round(f1[\"f1\"] * 100, 2)\n",
    "    }\n",
    "\n",
    "# Data collator that just batches samples together\n",
    "dataCollator = DefaultDataCollator()\n",
    "\n",
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"vit-cats-dogs-checkpoints\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=1, #8\n",
    "    per_device_eval_batch_size=1, #8\n",
    "    num_train_epochs=2,  # increase if you want better results\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    fp16=torch.cuda.is_available(),  # Use mixed precision if on GPU\n",
    ")\n",
    "\n",
    "subsetTrain = trainData.select(range(1000))\n",
    "subsetVal = valData.select(range(100))\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=trainData, # train_data\n",
    "    eval_dataset=valData, # val_data\n",
    "    tokenizer=imageProcessor,  # not strictly necessary, but can pass\n",
    "    data_collator=dataCollator,\n",
    "    compute_metrics=computeMetric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "Fct-CJpV1cd1",
    "outputId": "91386fd7-03ea-467e-f13a-358b2c300d00"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 8. Train\n",
    "# ------------------------------------------------------------------------\n",
    "trainOutput = trainer.train()\n",
    "trainer.save_model(\"vit_cats_dogs_final_model\")  # Save final model\n",
    "\n",
    "# Log & Save final training metrics\n",
    "trainer.log_metrics(\"train\", trainOutput.metrics)\n",
    "trainer.save_metrics(\"train\", trainOutput.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "Sj5wJDgI1gg8",
    "outputId": "f27fc4a9-cc36-455d-fd2a-c536c8506de4"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 9. Plot Training vs Validation Loss\n",
    "#    Similar to your BART code, parse trainer.state.log_history\n",
    "# ------------------------------------------------------------------------\n",
    "def plotTrainerLossCurves(trainer):\n",
    "    training_epochs, training_loss_vals = [], []\n",
    "    validation_epochs, validation_loss_vals = [], []\n",
    "\n",
    "    for record in trainer.state.log_history:\n",
    "        if record.get(\"loss\") is not None and record.get(\"epoch\") is not None:\n",
    "            training_loss_vals.append(record[\"loss\"])\n",
    "            training_epochs.append(record[\"epoch\"])\n",
    "        if record.get(\"eval_loss\") is not None and record.get(\"epoch\") is not None:\n",
    "            validation_loss_vals.append(record[\"eval_loss\"])\n",
    "            validation_epochs.append(record[\"epoch\"])\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(training_epochs, training_loss_vals, label=\"Training Loss\", marker='o')\n",
    "    plt.plot(validation_epochs, validation_loss_vals, label=\"Validation Loss\", marker='o')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training vs Validation Loss over Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plotTrainerLossCurves(trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "TxkTjLOrMReN",
    "outputId": "8a4f81c1-a776-4136-99cc-bec413f2198a"
   },
   "outputs": [],
   "source": [
    "def evaluateOnTestSet(trainer, tokenized_data, sample_size=500):\n",
    "    subset = tokenized_data.select(range(sample_size))\n",
    "    results = trainer.evaluate(eval_dataset=subset)\n",
    "    print(\"Evaluation Results on Test Subset:\", results)\n",
    "    trainer.log_metrics(\"test\", results)\n",
    "    trainer.save_metrics(\"test\", results)\n",
    "    return results\n",
    "\n",
    "testMetrics = evaluateOnTestSet(trainer, testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "SgQPcI5NN9Vu",
    "outputId": "61cf7779-ecc1-4dbe-a990-1f4958b71129"
   },
   "outputs": [],
   "source": [
    "# Bar chart of final test metrics\n",
    "def testMetricBarPlot(test_metrics):\n",
    "    labels = [\"Accuracy\", \"F1\"]\n",
    "    keys   = [\"eval_accuracy\", \"eval_f1\"]\n",
    "    scores = [test_metrics[key] for key in keys]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    bars = plt.bar(labels, scores, color=\"skyblue\")\n",
    "\n",
    "    for bar, value in zip(bars, scores):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, height+0.5, f\"{value:.2f}\",\n",
    "                 ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Evaluation Metrics on Test Subset\")\n",
    "    plt.ylim(0, max(scores) + 5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "testMetricBarPlot(testMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmvQpE8aPO5P"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"DogCatClassification.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "SaFUszRkPXIo",
    "outputId": "c153b490-a038-4f0f-8873-5901727d6409"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"DogCatClassification.pth\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
